\documentclass[aspectratio=169,11pt]{beamer}

%──────────────────────────────────────────────────────────────────
%  Theme & colours
%──────────────────────────────────────────────────────────────────
\usetheme{metropolis}
\metroset{sectionpage=none,subsectionpage=none}
\usepackage{appendixnumberbeamer}

\definecolor{DarkBlue}{HTML}{1a1a2e}
\definecolor{MidBlue}{HTML}{16213e}
\definecolor{AccentBlue}{HTML}{0f3460}
\definecolor{AccentPurple}{HTML}{533483}
\definecolor{NeonPink}{HTML}{e94560}
\definecolor{AccentText}{HTML}{FFB8CC}
\definecolor{SoftWhite}{HTML}{f0f0f0}
\definecolor{LightGray}{HTML}{d0d0d0}
\definecolor{Black}{HTML}{000000}

\setbeamercolor{background canvas}{bg=DarkBlue}
\setbeamercolor{normal text}{fg=SoftWhite}
\setbeamercolor{frametitle}{bg=MidBlue,fg=SoftWhite}
\setbeamercolor{title separator}{fg=AccentText}
\setbeamercolor{progress bar}{fg=AccentText,bg=AccentBlue}
\setbeamercolor{block title}{bg=AccentPurple,fg=SoftWhite}
\setbeamercolor{block body}{bg=Black!80,fg=SoftWhite}
\setbeamercolor{alerted text}{fg=AccentText}
\setbeamercolor{itemize item}{fg=AccentText}
\setbeamercolor{itemize subitem}{fg=LightGray}
\setbeamercolor{section in toc}{fg=SoftWhite}

%──────────────────────────────────────────────────────────────────
%  Packages
%──────────────────────────────────────────────────────────────────
\usepackage{tikz}
\usetikzlibrary{arrows.meta,positioning,decorations.pathreplacing,
                shapes.geometric,backgrounds,calc,fit,fadings}
\usepackage{amsmath,amssymb,bm}
\usepackage{booktabs}
\newcommand{\faIcon}[1]{\textbullet}
\usepackage{xcolor}
\usepackage{graphicx}

\usepackage[
  backend=biber,
  style=numeric-comp,
  sorting=none,
  giveninits=true,
  maxbibnames=2,
  doi=false,
  url=false,
  eprint=false,
  isbn=false
]{biblatex}

\addbibresource{references.bib}

%──────────────────────────────────────────────────────────────────
%  Metadata
%──────────────────────────────────────────────────────────────────
\title{\textbf{Diffusion Models}}
\subtitle{How AI Learns to Create Images from Noise}
\author{Presented by: \textit{Anindya, Tamal and Din}}
\date{\today}
\institute{CSE 200: Technical Writing and Presentation\\\textbf{Bangladesh University of Engineering and Technology}}

%──────────────────────────────────────────────────────────────────
%  Custom commands
%──────────────────────────────────────────────────────────────────
\newcommand{\highlight}[1]{\textcolor{AccentText}{\textbf{#1}}}
\newcommand{\soft}[1]{\textcolor{LightGray}{#1}}



%══════════════════════════════════════════════════════════════════
\begin{document}
%══════════════════════════════════════════════════════════════════

%──────────────────────────────────────────────────────────────────
% TITLE SLIDE
%──────────────────────────────────────────────────────────────────
{
\setbeamercolor{background canvas}{bg=DarkBlue}
\begin{frame}[plain]
  \begin{tikzpicture}[remember picture,overlay]
    \foreach \r/\op in {5/0.05,3.5/0.08,2/0.12}{
      \fill[NeonPink,opacity=\op]
        (current page.north east) circle (\r cm);
    }
    \foreach \r/\op in {4/0.05,2.5/0.08,1.2/0.12}{
      \fill[AccentPurple,opacity=\op]
        (current page.south west) circle (\r cm);
    }
  \end{tikzpicture}
  \vspace{1.4cm}
  \titlepage
\end{frame}
}

%══════════════════════════════════════════════════════════════════
% SLIDE 1 — What Problem Are We Solving?
%══════════════════════════════════════════════════════════════════

\begin{frame}{What Problem Are We Solving?}
  \begin{columns}[T]
    \column{0.52\textwidth}
      \begin{block}{Generative Modeling}
        Given many examples of real data (e.g.\ photos of faces),
        can a machine learn to \highlight{create new, realistic samples}
        that look just as real?
      \end{block}

      \vspace{10pt}
      \textbf{Why is this hard?}
      \begin{itemize}
        \item Real data is incredibly complex and high-dimensional
        \item The model must capture fine details \emph{and} global structure
        \item Previous approaches each had trade-offs:
          \begin{itemize}
            \item GANs — great quality, unstable training
            \item VAEs — stable training, blurry outputs
          \end{itemize}
      \end{itemize}

      \vspace{8pt}
      \highlight{Diffusion models} combine the best of both worlds.

    \column{0.45\textwidth}
      \vspace{6pt}
      \centering
      %% >>> REPLACE with an actual image <<<
      %% \includegraphics[width=\linewidth]{img/generative_examples.png}
      \begin{tikzpicture}
        \node[draw=LightGray, dashed, rounded corners=5pt,
              minimum width=6cm, minimum height=3.2cm,
              text=LightGray, font=\small, align=center]
          {\textit{Insert image:}\\\textit{Real photos vs.\ AI-generated}\\\textit{(e.g.\ faces, landscapes)}};
      \end{tikzpicture}
  \end{columns}
\end{frame}

%══════════════════════════════════════════════════════════════════
% SLIDE 2 — The Core Idea: Learning by Destroying
%══════════════════════════════════════════════════════════════════

\begin{frame}{The Core Idea: Learning by Destroying}

  \begin{center}
    \begin{tikzpicture}[
      stage/.style={rounded corners=6pt, draw=white!30,
                    minimum width=2.5cm, minimum height=2.4cm,
                    font=\small, text=white, align=center,
                    inner sep=6pt},
      bigarr/.style={-{Stealth[length=3mm]}, line width=1.6pt}]

      %% Forward (destroy)
      \node[stage, fill=AccentPurple!80] (clean) at (0,0)
        {\textbf{Clean Image}\\[6pt]\footnotesize contains\\all the detail};
      \node[stage, fill=AccentBlue] (mid) at (5,0)
        {\textbf{Noisy Image}\\[6pt]\footnotesize some detail\\remains};
      \node[stage, fill=NeonPink!60] (noise) at (10,0)
        {\textbf{Pure Noise}\\[6pt]\footnotesize no information\\left};

      \draw[bigarr, NeonPink!70] (clean) -- (mid)
        node[midway, above, font=\footnotesize]{add noise};
      \draw[bigarr, NeonPink!70] (mid) -- (noise)
        node[midway, above, font=\footnotesize]{add noise};

      %% Reverse (learn)
      \draw[bigarr, AccentText] (noise.south) -- ++(0,-0.5) -| (clean.south)
        node[midway, below=4pt, font=\footnotesize, text=AccentText]
        {Learn to reverse this process step by step};

    \end{tikzpicture}
  \end{center}

  \vspace{8pt}
  \begin{columns}[T]
    \column{0.48\textwidth}
      \highlight{Forward process} (fixed, no learning):
      \begin{itemize}
        \item Gradually add small amounts of random noise
        \item Eventually all structure is destroyed
      \end{itemize}

    \column{0.48\textwidth}
      \highlight{Reverse process} (learned):
      \begin{itemize}
        \item Train a neural network to undo each tiny noise step
        \item Starting from pure noise, the network reconstructs an image
      \end{itemize}
  \end{columns}

  \vspace{6pt}
\end{frame}

%══════════════════════════════════════════════════════════════════
% SLIDE 3 — The Forward Process: Adding Noise
%══════════════════════════════════════════════════════════════════

\begin{frame}{The Forward Process: Adding Noise}

  \vspace{10pt}
  \begin{center}
    %% >>> REPLACE with an actual noising-sequence image <<<
    %% \includegraphics[width=0.92\linewidth]{img/forward_process.png}
    \begin{tikzpicture}
      \node[draw=LightGray, dashed, rounded corners=5pt,
            minimum width=13cm, minimum height=3.8cm,
            text=LightGray, font=\small, align=center]
        {\textit{Insert image: progressive noising sequence}\\[4pt]
         Clean image $\to$ slightly noisy $\to$ more noisy $\to$ \dots\ $\to$ pure noise};
    \end{tikzpicture}
  \end{center}

  \begin{block}{What Happens}
    Take a real image and add a \emph{tiny} bit of random noise.
    Repeat this hundreds of times until only noise remains.
  \end{block}
\end{frame}

%══════════════════════════════════════════════════════════════════
% SLIDE 4 — The Reverse Process: Removing Noise
%══════════════════════════════════════════════════════════════════

\begin{frame}{The Reverse Process: Removing Noise}

  \vspace{10pt}
  \begin{center}
    %% >>> REPLACE with an actual denoising-sequence image <<<
    %% \includegraphics[width=0.92\linewidth]{img/reverse_process.png}
    \begin{tikzpicture}
      \node[draw=LightGray, dashed, rounded corners=5pt,
            minimum width=13cm, minimum height=3.8cm,
            text=LightGray, font=\small, align=center]
        {\textit{Insert image: progressive denoising sequence}\\[4pt]
         Pure noise $\to$ rough shape $\to$ clearer structure $\to$ final image};
    \end{tikzpicture}
  \end{center}

  \begin{block}{How Generation Works}
    \begin{itemize}
      \item Start from \highlight{pure noise}
      \item Predict and remove a little noise at each step
      \item Repeat until a realistic image appears
    \end{itemize}
  \end{block}
\end{frame}

%══════════════════════════════════════════════════════════════════
% SLIDE 5 — How Do We Train It?
%══════════════════════════════════════════════════════════════════

\begin{frame}{How Do We Train It?}

  \begin{center}
    \begin{tikzpicture}[
      trainstep/.style={rounded corners=5pt, draw=LightGray,
                   fill=AccentBlue, text=SoftWhite,
                   minimum width=12.8cm, minimum height=1.0cm,
                   font=\large, inner sep=10pt, align=left},
      arr/.style={->, LightGray, line width=1.2pt}]

      \node[trainstep] (s1) at (0,0)
        {1.\; Take a real image from the training set};
      \node[trainstep, below=14pt of s1] (s2)
        {2.\; Pick a random step and add the corresponding noise};
      \node[trainstep, below=14pt of s2] (s3)
        {3.\; Ask the neural network: \textit{``what noise was added?''}};
      \node[trainstep, below=14pt of s3, fill=AccentPurple!70] (s4)
        {4.\; Compare the prediction to the \textbf{actual noise}, minimize the error};

      \foreach \a/\b in {s1/s2, s2/s3, s3/s4}
        \draw[arr] (\a.south) -- (\b.north);
    \end{tikzpicture}
  \end{center}
\end{frame}

\begin{frame}{Key Insight \& Why It Works}
  \begin{columns}[T]
    \column{0.48\textwidth}
      \begin{block}{Key Insight}
        \begin{itemize}
          \item We add \textbf{known} noise
          \item So we have exact labels
          \item Training target is clear and reliable
        \end{itemize}
      \end{block}

    \column{0.48\textwidth}
      \begin{block}{Why It Works}
        \begin{itemize}
          \item Model learns many small denoising steps
          \item Small steps are easier to learn
          \item Chaining them builds a full image
        \end{itemize}
      \end{block}
  \end{columns}
\end{frame}

%══════════════════════════════════════════════════════════════════
% SLIDE 6 — Why Diffusion Models Work So Well
%══════════════════════════════════════════════════════════════════

\begin{frame}{Why Diffusion Models Work So Well}

  \begin{columns}[T]
    \column{0.55\textwidth}
      \begin{block}{Advantages}
        \begin{itemize}
          \item \highlight{Stable training} — no adversarial game; just predict noise
          \item \highlight{Small steps} — each denoising step is a tiny, easy task
          \item \highlight{High quality} — state-of-the-art image fidelity
          \item \highlight{Flexible} — works on images, audio, video, 3-D, molecules\ldots
        \end{itemize}
      \end{block}

      % \vspace{8pt}

    \column{0.42\textwidth}
      \centering
      \vspace{6pt}
      % Quality-stability scatter (simplified)
      \begin{tikzpicture}[scale=0.9]
        \draw[->,thick,white] (0,0) -- (4.5,0)
              node[right,font=\scriptsize]{Sample Quality};
        \draw[->,thick,white] (0,0) -- (0,4.2)
              node[above,font=\scriptsize]{Training Stability};

        \node[circle,fill=AccentPurple,minimum size=24pt,
              font=\scriptsize\bfseries,text=white]
              at (3.4,0.9) {GAN};
        \node[circle,fill=AccentBlue,minimum size=24pt,
              font=\scriptsize\bfseries,text=white]
              at (1.3,3.0) {VAE};
        \node[circle,fill=NeonPink,minimum size=28pt,
              font=\scriptsize\bfseries,text=white]
              at (3.6,3.5) {Diff.};

        \draw[dashed,AccentText,->] (2.4,3.8) -- (3.35,3.55);
        \node[AccentText,font=\scriptsize,align=center] at (1.8,4.1)
            {Best of\\ both worlds};
      \end{tikzpicture}
  \end{columns}
\end{frame}

%══════════════════════════════════════════════════════════════════
% SLIDE 7 — Applications
%══════════════════════════════════════════════════════════════════

\begin{frame}{Applications}
  \begin{columns}[T]
    \column{0.55\textwidth}
      \vspace{6pt}
      \begin{tikzpicture}[
        app/.style={rounded corners=4pt,
                    minimum width=2.4cm, minimum height=0.58cm,
                    font=\scriptsize\bfseries, text=white,
                    inner sep=4pt, align=center},
        apparrow/.style={-{Stealth[length=2mm]},
                         LightGray!65, line width=0.6pt},
        every node/.style={font=\scriptsize}]

        \node[draw=NeonPink, circle, fill=DarkBlue,
              font=\small\bfseries, text=AccentText,
              minimum size=1.2cm] (c) at (0,0) {DMs};

        \node[app, fill=NeonPink]        (img)   at (150:2.4cm) {Image Synthesis};
        \node[app, fill=AccentBlue!120]  (aud)   at (210:2.4cm) {Audio / Music};
        \node[app, fill=NeonPink!70]     (med)   at (270:2.4cm) {Medical Imaging};
        \node[app, fill=AccentBlue]      (threed)at (330:2.4cm) {3-D / NeRF};
        \node[app, fill=AccentPurple!80] (mol)   at ( 30:2.4cm) {Molecular Design};
        \node[app, fill=AccentPurple]    (vid)   at ( 90:2.4cm) {Video Generation};

        \foreach \dest in {img, aud, med, threed, mol, vid}
          \draw[apparrow] (c) -- (\dest);
      \end{tikzpicture}

    \column{0.42\textwidth}
      \textbf{Real-world tools powered by diffusion:}
      \begin{itemize}
        \item \highlight{DALL·E 3} — text-to-image
        \item \highlight{Stable Diffusion} — open-source image generation
        \item \highlight{Midjourney} — art and design
        \item \highlight{Sora} — text-to-video
      \end{itemize}
  \end{columns}
\end{frame}

%══════════════════════════════════════════════════════════════════
% SLIDE 8 — Limitations & Open Challenges
%══════════════════════════════════════════════════════════════════

\begin{frame}{Limitations \& Open Challenges}
  \begin{columns}[T]
    \column{0.50\textwidth}
      \begin{block}{Current Limitations}
        \begin{itemize}
          \item \textbf{Slow generation} — requires many denoising steps
                (hundreds to thousands)
          \item \textbf{High compute cost} — training requires significant
                GPU resources
          \item \textbf{Large model size} — not easy to run on consumer hardware
        \end{itemize}
      \end{block}

    \column{0.47\textwidth}
      \begin{block}{Open Questions}
        \begin{itemize}
          \item Can we make generation \highlight{faster}?
                (Active research area)
          \item How do we ensure generated content is \highlight{safe and ethical}?
          \item Can we extend to \highlight{longer videos} and
                \highlight{interactive content}?
        \end{itemize}
      \end{block}
  \end{columns}

  \vspace{12pt}
  % \begin{center}
  %   \begin{tikzpicture}
  %     \node[draw=NeonPink, rounded corners=6pt,
  %           fill=AccentBlue!70, text=SoftWhite,
  %           inner sep=10pt, text width=11cm, align=center,
  %           font=\normalsize]{
  %       Diffusion models are \textbf{young}, \textbf{powerful},
  %       and \textbf{improving fast}.\\[3pt]
  %       The best results in generative AI today
  %       are almost all diffusion-based.
  %     };
  %   \end{tikzpicture}
  % \end{center}
\end{frame}

%──────────────────────────────────────────────────────────────────
% THANK YOU SLIDE
%──────────────────────────────────────────────────────────────────
{
\setbeamercolor{background canvas}{bg=DarkBlue}
\begin{frame}[plain]
  \begin{tikzpicture}[remember picture,overlay]
    \foreach \r/\op in {6/0.04,4/0.07,2.2/0.11}{
      \fill[NeonPink,opacity=\op]
        (current page.center) circle (\r cm);
    }
  \end{tikzpicture}
  \vspace{1.2cm}
  \begin{center}
    {\Huge\bfseries\color{SoftWhite} Thank You!}\\[10pt]
    {\large\color{LightGray} Questions?}
  \end{center}
\end{frame}
}

%──────────────────────────────────────────────────────────────────
% REFERENCES SLIDE
%──────────────────────────────────────────────────────────────────
\begin{frame}{References}
  \footnotesize
  \setlength{\bibitemsep}{4pt}
  \nocite{ho2020ddpm,song2019generative,song2020denoising,nichol2021improved}
  \printbibliography[heading=none]
\end{frame}

\end{document}