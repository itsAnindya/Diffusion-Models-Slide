\documentclass[aspectratio=169,10pt]{beamer}

%──────────────────────────────────────────────────────────────────
%  Theme & colours
%──────────────────────────────────────────────────────────────────
\usetheme{metropolis}
\metroset{sectionpage=none,subsectionpage=none}
\usepackage{appendixnumberbeamer}

\definecolor{DarkBlue}{HTML}{1a1a2e}
\definecolor{MidBlue}{HTML}{16213e}
\definecolor{AccentBlue}{HTML}{0f3460}
\definecolor{AccentPurple}{HTML}{533483}
\definecolor{NeonPink}{HTML}{e94560}
\definecolor{AccentText}{HTML}{FFB8CC}
\definecolor{SoftWhite}{HTML}{f0f0f0}
\definecolor{LightGray}{HTML}{d0d0d0}
\definecolor{Black}{HTML}{000000}

\setbeamercolor{background canvas}{bg=DarkBlue}
\setbeamercolor{normal text}{fg=SoftWhite}
\setbeamercolor{frametitle}{bg=MidBlue,fg=SoftWhite}
\setbeamercolor{title separator}{fg=AccentText}
\setbeamercolor{progress bar}{fg=AccentText,bg=AccentBlue}
\setbeamercolor{block title}{bg=AccentPurple,fg=SoftWhite}
% \setbeamercolor{block body}{bg=AccentBlue!60,fg=SoftWhite}
\setbeamercolor{block body}{bg=Black!80,fg=SoftWhite}
\setbeamercolor{alerted text}{fg=AccentText}
\setbeamercolor{itemize item}{fg=AccentText}
\setbeamercolor{itemize subitem}{fg=LightGray}
\setbeamercolor{section in toc}{fg=SoftWhite}

%──────────────────────────────────────────────────────────────────
%  Packages
%──────────────────────────────────────────────────────────────────
\usepackage{tikz}
\usetikzlibrary{arrows.meta,positioning,decorations.pathreplacing,
                shapes.geometric,backgrounds,calc,fit,fadings}
\usepackage{amsmath,amssymb,bm}
\usepackage{booktabs}
% fontawesome5 not available; using text icons
\newcommand{\faIcon}[1]{\textbullet}
\usepackage{pgfplots}
\pgfplotsset{compat=1.18}
\usepackage{xcolor}
\usepackage{mathtools}

\usepackage[
  backend=biber,
  style=numeric-comp,
  sorting=none,
  giveninits=true,
  maxbibnames=2,
  doi=false,
  url=false,
  eprint=false,
  isbn=false
]{biblatex}

\addbibresource{references.bib}

%──────────────────────────────────────────────────────────────────
%  Metadata
%──────────────────────────────────────────────────────────────────
\title{\textbf{Diffusion Models}}
\subtitle{How AI Learns to Create Images from Noise}
\author{Presented by: \textit{Anindya, Tamal and Din}}
\date{\today}
\institute{CSE 200: Technical Writing and Presentation\\\textbf{Bangladesh University of Engineering and Technology}}

%──────────────────────────────────────────────────────────────────
%  Custom commands
%──────────────────────────────────────────────────────────────────
\newcommand{\x}{\mathbf{x}}
\newcommand{\eps}{\boldsymbol{\varepsilon}}
\newcommand{\highlight}[1]{\textcolor{AccentText}{\textbf{#1}}}
\newcommand{\soft}[1]{\textcolor{LightGray}{#1}}

% ─── Noise-level boxes ───────────────────────────────────────────
\newcommand{\noisebox}[2]{%
  \begin{tikzpicture}[baseline=-2pt]
    \node[rounded corners=3pt,fill=#1,minimum width=1.1cm,
          minimum height=0.6cm,font=\tiny\bfseries,text=white]{#2};
  \end{tikzpicture}}

%══════════════════════════════════════════════════════════════════
\begin{document}
%══════════════════════════════════════════════════════════════════

%──────────────────────────────────────────────────────────────────
% TITLE SLIDE
%──────────────────────────────────────────────────────────────────
{
\setbeamercolor{background canvas}{bg=DarkBlue}
\begin{frame}[plain]
  \begin{tikzpicture}[remember picture,overlay]
    % decorative circles
    \foreach \r/\op in {5/0.05,3.5/0.08,2/0.12}{
      \fill[NeonPink,opacity=\op]
        (current page.north east) circle (\r cm);
    }
    \foreach \r/\op in {4/0.05,2.5/0.08,1.2/0.12}{
      \fill[AccentPurple,opacity=\op]
        (current page.south west) circle (\r cm);
    }
  \end{tikzpicture}
  \vspace{1.4cm}
  \titlepage
\end{frame}
}

%──────────────────────────────────────────────────────────────────
% OUTLINE
%──────────────────────────────────────────────────────────────────
\begin{frame}{Roadmap}
  \vspace{0.3cm}
  \begin{columns}[T]
    \column{0.55\textwidth}
      \tableofcontents
    \column{0.42\textwidth}
      \begin{tikzpicture}
        \node[draw=NeonPink,rounded corners=5pt,
              text=SoftWhite,fill=AccentBlue,
              text width=4.5cm, align=center, inner sep=8pt]{
          \small
          \faIcon{clock}~\textbf{10 min talk}\\[4pt]
          \footnotesize
          Speaker 1 (Anindya Biswas) \hfill 3 min\\
          Speaker 2 (Tasnim Tamal) \hfill 3 min\\
          Speaker 3 (Din Mohammad) \hfill 3 min\\
          Buffer / Transition \hfill 1 min
        };
      \end{tikzpicture}
  \end{columns}
\end{frame}

%══════════════════════════════════════════════════════════════════
\section{Motivation}
%══════════════════════════════════════════════════════════════════

\begin{frame}{Why Diffusion Models?}
  \begin{columns}[T]
    \column{0.54\textwidth}
      \begin{block}{In One Line}
        A diffusion model learns to \highlight{turn random noise into meaningful data}
        (like realistic images).
      \end{block}
      % \vspace{6pt}
      \begin{itemize}
        \item \textbf{GANs}: high quality, but training is often unstable
        \item \textbf{VAEs}: stable and fast, but outputs can look blurry
        \item \textbf{Flows}: mathematically clean, but architecture is restricted
        \item \highlight{Diffusion}: stable training + very strong output quality
      \end{itemize}
      % \vspace{6pt}
      

    \column{0.44\textwidth}
      \begin{tikzpicture}[scale=0.85]
        % axes
        \draw[->,thick,white] (0,0) -- (4.5,0)
              node[right,font=\tiny]{Sample Quality};
        \draw[->,thick,white] (0,0) -- (0,4.2)
              node[above,font=\tiny]{Training Stability};
        % methods
        \node[circle,fill=AccentPurple,minimum size=22pt,
              font=\tiny\bfseries,text=white]
              at (1.2,1.0) {GAN};
        \node[circle,fill=AccentBlue,minimum size=22pt,
              font=\tiny\bfseries,text=white]
              at (1.8,2.8) {VAE};
        \node[circle,fill=AccentPurple!80,minimum size=22pt,
              font=\tiny\bfseries,text=white]
              at (2.4,2.2) {Flow};
        \node[circle,fill=NeonPink,minimum size=26pt,
              font=\tiny\bfseries,text=white]
              at (3.6,3.5) {Diff.};
        % annotation
        \draw[dashed,NeonPink!60,->] (3.0,3.5) -- (3.45,3.45);
          \node[AccentText,font=\tiny,align=center] at (2.1,3.9)
              {Best of\\ both worlds};
      \end{tikzpicture}
  \end{columns}
  \vspace{6pt}
  \soft{Used in tools like DALL·E 3, Stable Diffusion, and Sora}
\end{frame}

%══════════════════════════════════════════════════════════════════
\section{Forward Process}
%══════════════════════════════════════════════════════════════════

\begin{frame}{The Forward (Noising) Process}

  \begin{block}{Key Idea}
    Gradually corrupt data $\x_0$ into pure Gaussian noise $\x_T$
    through a fixed Markov chain.
  \end{block}

  \vspace{6pt}
  \begin{equation*}
    q(\x_t \mid \x_{t-1}) = \mathcal{N}\!\left(\x_t;\;
      \sqrt{1-\beta_t}\,\x_{t-1},\;\beta_t \mathbf{I}\right)
  \end{equation*}

  \vspace{4pt}
  \begin{center}
  \begin{tikzpicture}[node distance=0.6cm and 0.65cm,
    box/.style={rounded corners=4pt,draw=white!40,
                fill=AccentBlue,minimum height=1.0cm,
                minimum width=1.1cm,font=\tiny,text=white,
                inner sep=2pt,align=center}]

    \node[box,fill=AccentPurple!80] (x0) {$\x_0$\\\tiny clean};
    \node[box] (x1) [right=of x0]   {$\x_1$};
    \node[box] (x2) [right=of x1]   {$\x_2$};
    \node[box] (xd) [right=of x2]   {\ldots};
    \node[box] (xt) [right=of xd]   {$\x_{T-1}$};
    \node[box,fill=NeonPink!50] (xT) [right=of xt] {$\x_T$\\\tiny noise};

    \foreach \a/\b in {x0/x1,x1/x2,x2/xd,xd/xt,xt/xT}{
      \draw[->,thick,LightGray] (\a) -- (\b)
            node[midway,above,font=\tiny]{$+\beta_t$};
    }

    % noise icons (fuzzy fills)
    \foreach \n/\op in {x1/20,x2/40,xt/70,xT/100}{
      \fill[white,opacity=0.0\op,rounded corners=4pt]
        (\n.south west) rectangle (\n.north east);
    }

    % closed-form shortcut
    \draw[<->,dashed,NeonPink,thick]
      (x0.south) -- ++(0,-0.6) -| (xT.south)
      node[midway,below,font=\scriptsize,text=AccentText]{
        $q(\x_t|\x_0)=\mathcal{N}(\sqrt{\bar\alpha_t}\,\x_0,
        (1-\bar\alpha_t)\mathbf{I})$};
  \end{tikzpicture}
  \end{center}

  \vspace{4pt}
  \small
  Plainly: start from a real sample and add a little noise repeatedly
  until almost all information is gone.

\end{frame}


%══════════════════════════════════════════════════════════════════
\section{Reverse Process}
%══════════════════════════════════════════════════════════════════
\begin{frame}{The Reverse (Denoising) Process}

  \begin{columns}[T]
    \column{0.40\textwidth}
      \textbf{Goal}: Learn $p_\theta(\x_{t-1}|\x_t)$ to reverse the noise.

      \vspace{6pt}
      A \highlight{neural network} $\eps_\theta$ predicts the noise
      present at each step:
      \begin{equation*}
        \x_{t-1} \approx \x_t - \text{predicted noise}
      \end{equation*}

      \vspace{4pt}
      \begin{itemize}
        \item Backbone: usually a \textbf{U-Net}
        \item Input: noisy sample $\x_t$ and timestep $t$
        \item Repeat to gradually recover clean data
      \end{itemize}

    \column{0.58\textwidth}
      \centering
      \begin{tikzpicture}[
        box/.style={rounded corners=4pt, draw=white!30,
                    minimum width=2.6cm, minimum height=0.65cm,
                    font=\scriptsize\bfseries, text=white,
                    inner sep=4pt, align=center},
        arr/.style={->, line width=1.2pt, NeonPink!85},
        ann/.style={draw=AccentPurple, rounded corners=3pt,
                    fill=AccentPurple!80, font=\tiny, text=white,
                    inner sep=4pt, align=center}]

        %% ---- chain nodes, generously spaced ----
        \node[box, fill=NeonPink!55]      (xT)   at (0,  0.0) {$\x_T \sim \mathcal{N}(0,\mathbf{I})$};
        \node[box, fill=AccentBlue]       (xT1)  at (0, -1.6) {$\x_{T-1}$};
        \node[font=\small, text=LightGray](dots)  at (0, -2.7) {$\vdots$};
        \node[box, fill=AccentBlue]       (x1)   at (0, -3.8) {$\x_1$};
        \node[box, fill=AccentPurple!85]  (x0)   at (0, -5.4) {$\x_0$ \ (Generated)};

        %% ---- arrows along the chain ----
        \foreach \a/\b in {xT/xT1, xT1/dots, dots/x1, x1/x0}
          \draw[arr] (\a) -- (\b);

        %% ---- U-Net annotation box ----
        \node[ann] (unet) at (2.55,-2.7)
              {$\eps_\theta(\x_t,t)$\\[2pt]U-Net};

        %% ---- dashed lines to arrow midpoints, not node centres ----
        \draw[dashed, AccentPurple!80, ->]
          (unet.west) -- (0.55,-0.80);   %% mid of xT  → xT1
        \draw[dashed, AccentPurple!80, ->]
          (unet.west) -- (0.55,-4.60);   %% mid of x1  → x0

      \end{tikzpicture}
  \end{columns}

\end{frame}

%══════════════════════════════════════════════════════════════════
\section{Training \& Score Matching}
%══════════════════════════════════════════════════════════════════

\begin{frame}{Training Objective}

  \begin{block}{Training Idea (Simple Version)}
    \vspace{-2pt}
    \begin{equation*}
      \mathcal{L}_{\text{simple}} =
        \mathbb{E}_{t,\,\x_0,\,\eps}\!\left[
          \left\|\,\eps \;-\;
          \eps_\theta\!\left(\sqrt{\bar\alpha_t}\,\x_0 +
          \sqrt{1-\bar\alpha_t}\,\eps,\; t\right)\right\|^2
        \right]
    \end{equation*}
  \end{block}

  \vspace{4pt}
  \begin{columns}[T]
    \column{0.48\textwidth}
      \textbf{Algorithm — Training}\\[4pt]
      \begin{tikzpicture}[
        flowstep/.style={rounded corners=3pt, draw=LightGray,
                         fill=AccentBlue, text=SoftWhite,
                         text width=\linewidth,        %% fills the column
                         font=\scriptsize,
                         inner sep=5pt, align=left},
        arr/.style={->, LightGray, line width=0.7pt}]

        \node[flowstep] (s1)
              {1.~Sample $\x_0\sim q(\x_0)$};
        \node[flowstep, below=8pt of s1] (s2)   %% more gap → visible arrow
              {2.~Sample timestep $t\sim\mathcal{U}\{1,T\}$};
        \node[flowstep, below=8pt of s2] (s3)
              {3.~Sample $\eps\sim\mathcal{N}(0,\mathbf{I})$};
        \node[flowstep, below=8pt of s3] (s4)
              {4.~Compute noisy sample $\x_t$};
        \node[flowstep, below=8pt of s4, fill=AccentPurple!70] (s5)
              {5.~\textbf{Minimise} $\|\eps - \eps_\theta(\x_t,t)\|^2$};

        \foreach \a/\b in {s1/s2, s2/s3, s3/s4, s4/s5}
          \draw[arr] (\a.south) -- (\b.north);

      \end{tikzpicture}

    \column{0.48\textwidth}
      \textbf{What this loss means}\\[6pt]
      \small
      \begin{itemize}
        \item We add known noise to a clean sample
        \item The model guesses that exact noise
        \item If the guess is close, the model is learning correctly
        \item After training, we remove noise step by step
      \end{itemize}
      \vspace{6pt}
      \highlight{Key insight}: learning to denoise is enough for generation.
  \end{columns}

\end{frame}
%──────────────────────────────────────────────────────────────────
\begin{frame}{Noise Schedule \& Sampling Speed}
  \begin{columns}[T]
    \column{0.50\textwidth}
      \textbf{Noise Schedules}
      \begin{itemize}
        \item \textit{Linear}: increase noise at a constant rate
        \item \textit{Cosine}: keeps more structure early on
        \item \textit{Learned}: schedule is optimized by data
      \end{itemize}

      \vspace{6pt}
      \begin{tikzpicture}[scale=0.78]
        \begin{axis}[
          width=5.5cm,height=3.8cm,
          xlabel={\scriptsize Timestep $t$},
          ylabel={\scriptsize $\bar\alpha_t$},
          axis background/.style={fill=MidBlue},
          axis line style={white},
          tick style={white},
          ticklabel style={font=\tiny,text=LightGray},
          legend style={font=\tiny,fill=MidBlue,
                        text=SoftWhite,draw=none},
          xmin=0,xmax=1000,ymin=0,ymax=1]
          \addplot[thick,NeonPink,domain=0:1000,samples=80]
            {(1000-x)/1000};
          \addlegendentry{Linear}
          \addplot[thick,AccentPurple!120,domain=0:1000,samples=80]
            {0.5*(1+cos(deg(3.14159*(x/1000))))};
          \addlegendentry{Cosine}
        \end{axis}
      \end{tikzpicture}

    \column{0.48\textwidth}
      \textbf{Accelerated Sampling}
      \begin{itemize}
        \item DDPM: $T=1000$ steps (slow)
        \item \highlight{DDIM} (Song et al., 2020): deterministic,
              $\sim$50 steps, same quality
        \item \highlight{DPM-Solver}: $\sim$20 steps
        \item \highlight{Consistency Models}: 1–2 steps!
      \end{itemize}

      \vspace{4pt}
      \small Speed-quality trade-off is an active research frontier.
  \end{columns}
\end{frame}

%══════════════════════════════════════════════════════════════════
\section{Applications}
%══════════════════════════════════════════════════════════════════

\begin{frame}{Applications \& Variants}
  \begin{columns}[T]
    \column{0.58\textwidth}
      \vspace{6pt}
      \begin{tikzpicture}[
        app/.style={rounded corners=4pt,
                    minimum width=2.4cm, minimum height=0.58cm,
                    font=\scriptsize\bfseries, text=white,
                    inner sep=4pt, align=center},
        apparrow/.style={-{Stealth[length=2mm]},
                         LightGray!65, line width=0.6pt},
        every node/.style={font=\scriptsize}]

        %% ---- hub ----
        \node[draw=NeonPink, circle, fill=DarkBlue,
              font=\small\bfseries, text=AccentText,
              minimum size=1.2cm] (c) at (0,0) {DMs};

        %% ---- spoke nodes (evenly spaced angles) ----
        \node[app, fill=NeonPink]        (img)   at (150:2.4cm) {Image Synthesis};
        \node[app, fill=AccentBlue!120]  (aud)   at (210:2.4cm) {Audio / Music};
        \node[app, fill=NeonPink!70]     (med)   at (270:2.4cm) {Medical Imaging};
        \node[app, fill=AccentBlue]      (threed)at (330:2.4cm) {3-D Shape / NeRF};
        \node[app, fill=AccentPurple!80] (mol)   at ( 30:2.4cm) {Molecular Design};
        \node[app, fill=AccentPurple]    (vid)   at ( 90:2.4cm) {Video Generation};

        %% ---- radiating arrows (c → node border, auto-clipped) ----
        \foreach \dest in {img, aud, med, threed, mol, vid}
          \draw[apparrow] (c) -- (\dest);

      \end{tikzpicture}

    \column{0.40\textwidth}
      \textbf{Conditional Generation}
      \begin{itemize}
        \item \textbf{Classifier guidance}: steer outputs toward a target label
        \item \textbf{Classifier-free}: no separate classifier required
        \item \textbf{Text conditioning}: prompt-driven image generation
      \end{itemize}

      \vspace{6pt}
      \soft{\footnotesize Notable: Stable Diffusion (latent space),
      DALL·E\,3 (GPT captions), Sora (video)}
  \end{columns}
\end{frame}
%══════════════════════════════════════════════════════════════════
\section{Conclusion}
%══════════════════════════════════════════════════════════════════

\begin{frame}{Takeaways \& Open Challenges}
  \begin{columns}[T]
    \column{0.50\textwidth}
      \begin{block}{\faIcon{check-circle}~Key Takeaways}
        \begin{itemize}
          \item Diffusion = iterative \textbf{denoising}
          \item Training objective is \textbf{simple MSE}
          \item Grounded in \textbf{score matching} theory
          \item Sets \textbf{state-of-the-art} across modalities
        \end{itemize}
      \end{block}

    \column{0.48\textwidth}
      \begin{block}{\faIcon{flask}~Open Challenges}
        \begin{itemize}
          \item Slow sampling (active research)
          \item High compute cost
          \item Evaluation metrics (FID, CLIP-S)
          \item Alignment \& safety of generated content
        \end{itemize}
      \end{block}
  \end{columns}

  \vspace{10pt}
  \begin{center}
    \begin{tikzpicture}
      \node[draw=NeonPink,rounded corners=6pt,
            fill=AccentBlue!70,
            text=SoftWhite,inner sep=10pt,
            text width=11cm,align=center]{
        \textbf{Core Formula to Remember}\\[4pt]
        $\displaystyle
          \mathcal{L} =
          \mathbb{E}_{t,\x_0,\eps}\!\left[
            \bigl\|\eps - \eps_\theta\!\bigl(\sqrt{\bar\alpha_t}\,\x_0
            + \sqrt{1-\bar\alpha_t}\,\eps,\;t\bigr)\bigr\|^2
          \right]$
      };
    \end{tikzpicture}
  \end{center}
\end{frame}

%──────────────────────────────────────────────────────────────────
% THANK YOU SLIDE
%──────────────────────────────────────────────────────────────────
{
\setbeamercolor{background canvas}{bg=DarkBlue}
\begin{frame}[plain]
  \begin{tikzpicture}[remember picture,overlay]
    \foreach \r/\op in {6/0.04,4/0.07,2.2/0.11}{
      \fill[NeonPink,opacity=\op]
        (current page.center) circle (\r cm);
    }
  \end{tikzpicture}
  \vspace{1.2cm}
  \begin{center}
    {\Huge\bfseries\color{SoftWhite} Thank You!}\\[10pt]
    {\large\color{LightGray} Thanks for listening}
  \end{center}
\end{frame}
}

%──────────────────────────────────────────────────────────────────
% REFERENCES SLIDE (minimalistic)
%──────────────────────────────────────────────────────────────────
\begin{frame}{References}
  \footnotesize
  \setlength{\bibitemsep}{4pt}
  \nocite{ho2020ddpm,song2019generative,song2020denoising,nichol2021improved}
  \printbibliography[heading=none]
\end{frame}

\end{document}